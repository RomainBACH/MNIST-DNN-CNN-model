{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0dad69",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f016f",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f7007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0e39c",
   "metadata": {},
   "source": [
    "## Load and reshape the data and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e41659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  (60000, 28, 28, 1)\n",
      "y_train :  (60000,)\n",
      "x_test  :  (10000, 28, 28, 1)\n",
      "y_test  :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() # many data set are included in keras\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test  = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "print(\"x_train : \",x_train.shape)\n",
    "print(\"y_train : \",y_train.shape)\n",
    "print(\"x_test  : \",x_test.shape)\n",
    "print(\"y_test  : \",y_test.shape)\n",
    "\n",
    "xmax=x_train.max()\n",
    "x_train = x_train / xmax\n",
    "x_test  = x_test  / xmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa7753",
   "metadata": {},
   "source": [
    "## Creation of CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086b7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = keras.models.Sequential()\n",
    "\n",
    "model_cnn.add( keras.layers.Input((28,28,1)) )\n",
    "\n",
    "model_cnn.add( keras.layers.Conv2D(8, (3,3),  activation='relu') )\n",
    "model_cnn.add( keras.layers.MaxPooling2D((2,2)))\n",
    "model_cnn.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "model_cnn.add( keras.layers.Conv2D(16, (3,3), activation='relu') )\n",
    "model_cnn.add( keras.layers.MaxPooling2D((2,2)))\n",
    "model_cnn.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "model_cnn.add( keras.layers.Flatten()) \n",
    "model_cnn.add( keras.layers.Dense(100, activation='relu'))\n",
    "model_cnn.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "model_cnn.add( keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9023fa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 8)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               40100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,358\n",
      "Trainable params: 42,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn.summary()\n",
    "\n",
    "model_cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7224d3",
   "metadata": {},
   "source": [
    "With the CNN, the number of parameters is divided by 2, almost 90,000 for the DNN against 42 358 for the CNN.\n",
    "\n",
    "model_cnn.add( keras.layers.Conv2D(8, (3,3),  activation='relu') )\n",
    "means  a convolution layer with 2 dimensions, the kernel size is (3,3) and the activation fonction is 'relu'. The number of parameters of this layer 8*(3x3+1) '8' for the number of convolution, '3x3' is the dimension of kernel and '1' the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4b68f",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "118/118 [==============================] - 10s 80ms/step - loss: 1.0776 - accuracy: 0.6438 - val_loss: 0.2679 - val_accuracy: 0.9301\n",
      "Epoch 2/16\n",
      "118/118 [==============================] - 9s 72ms/step - loss: 0.3765 - accuracy: 0.8865 - val_loss: 0.1427 - val_accuracy: 0.9583\n",
      "Epoch 3/16\n",
      "118/118 [==============================] - 8s 71ms/step - loss: 0.2585 - accuracy: 0.9210 - val_loss: 0.1061 - val_accuracy: 0.9675\n",
      "Epoch 4/16\n",
      "118/118 [==============================] - 9s 73ms/step - loss: 0.2139 - accuracy: 0.9353 - val_loss: 0.0870 - val_accuracy: 0.9731\n",
      "Epoch 5/16\n",
      "118/118 [==============================] - 8s 71ms/step - loss: 0.1853 - accuracy: 0.9444 - val_loss: 0.0726 - val_accuracy: 0.9771\n",
      "Epoch 6/16\n",
      "118/118 [==============================] - 8s 68ms/step - loss: 0.1652 - accuracy: 0.9494 - val_loss: 0.0642 - val_accuracy: 0.9801\n",
      "Epoch 7/16\n",
      "118/118 [==============================] - 8s 71ms/step - loss: 0.1526 - accuracy: 0.9538 - val_loss: 0.0586 - val_accuracy: 0.9816\n",
      "Epoch 8/16\n",
      "118/118 [==============================] - 8s 67ms/step - loss: 0.1433 - accuracy: 0.9567 - val_loss: 0.0519 - val_accuracy: 0.9838\n",
      "Epoch 9/16\n",
      "118/118 [==============================] - 8s 70ms/step - loss: 0.1325 - accuracy: 0.9592 - val_loss: 0.0488 - val_accuracy: 0.9840\n",
      "Epoch 10/16\n",
      "118/118 [==============================] - 8s 69ms/step - loss: 0.1230 - accuracy: 0.9622 - val_loss: 0.0447 - val_accuracy: 0.9854\n",
      "Epoch 11/16\n",
      "118/118 [==============================] - 8s 68ms/step - loss: 0.1199 - accuracy: 0.9636 - val_loss: 0.0434 - val_accuracy: 0.9858\n",
      "Epoch 12/16\n",
      "118/118 [==============================] - 8s 72ms/step - loss: 0.1165 - accuracy: 0.9641 - val_loss: 0.0420 - val_accuracy: 0.9857\n",
      "Epoch 13/16\n",
      " 86/118 [====================>.........] - ETA: 2s - loss: 0.1098 - accuracy: 0.9660"
     ]
    }
   ],
   "source": [
    "batch_size  = 512\n",
    "epochs      =  16\n",
    "\n",
    "history = model_cnn.fit(  x_train, y_train,\n",
    "                      batch_size      = batch_size,\n",
    "                      epochs          = epochs,\n",
    "                      verbose         = 1,\n",
    "                      validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2feda36",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cnn = model_cnn.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test loss     : {score_cnn[0]:4.4f}')\n",
    "print(f'Test accuracy : {score_cnn[1]:4.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924c720",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe1d27",
   "metadata": {},
   "source": [
    "With a DNN, we had a precision of the order of : 97.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# use Pandas native plot method\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"rate_validity\")\n",
    "plt.title(\"Rate_validation acoording the number of epochs\")\n",
    "history_df['accuracy'].plot()\n",
    "history_df['val_accuracy'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2742385",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56924678",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sigmoid = model_cnn.predict(x_test)\n",
    "y_pred    = np.argmax(y_sigmoid, axis=-1)\n",
    "\n",
    "cf_matrix=tf.math.confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9aa165",
   "metadata": {},
   "source": [
    "## Plot some errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = xtest.reshape((-1, 28, 28))\n",
    "\n",
    "# poorly predicted data are recovered \n",
    "misclass = (y_test != y_pred)\n",
    "misclass_images = images[misclass,:,:]\n",
    "misclass_predicted = y_pred[misclass]\n",
    "\n",
    "# a sample of these images is selected\n",
    "select = np.random.randint(misclass_images.shape[0], size=12)\n",
    "\n",
    "# the images and the (erroneous) predictions associated with these images are displayed\n",
    "for index, value in enumerate(select):\n",
    "    plt.subplot(3,4,index+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(misclass_images[value],cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "    plt.title('Predicted: {}'.format(misclass_predicted[value]) )\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
